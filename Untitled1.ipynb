{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78899abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caaka\\anaconda3\\lib\\site-packages\\swagger_spec_validator\\validator20.py:48: SwaggerValidationWarning: Found \"$ref: #/definitions/UserPreferences\" with siblings that will be overwritten. See https://stackoverflow.com/a/48114924 for more information. (path #/definitions/User/properties/preferences)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import math\n",
    "import os.path\n",
    "import time\n",
    "from bitmex import bitmex\n",
    "from binance.client import Client\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil import parser\n",
    "from tqdm import tqdm_notebook #(Optional, used for progress-bars)\n",
    "\n",
    "#output_path \n",
    "bin_path = 'BINANCE/'\n",
    "bit_path = 'BITMEX/'\n",
    "\n",
    "### API\n",
    "bitmex_api_key = 'TbO9dOvjcvk3bKqy5ld8vDV0'    #Enter your own API-key here\n",
    "bitmex_api_secret = 'tcyeS9pLBVfbgRTXJ5mvGW-Ks82AYfEInq3FBwNhEnQAbNhI' #Enter your own API-secret here\n",
    "binance_api_key = 'ryFql9CN1i2KdtDSU63IqgfVr4UUrtz8Dp7Z3MZWM3VgUGkbBmwGzEbL1m05KfZM'    #Enter your own API-key here\n",
    "binance_api_secret = 'jcKFz23PUlvBj3TjgN3qMVRpMkxo4GUSokVOjlqG49Qs647pAl94ru8Wpp1Ht9Kt' #Enter your own API-secret here\n",
    "\n",
    "### CONSTANTS\n",
    "binsizes = {\"1m\": 1, \"5m\": 5, \"1h\": 60, \"1d\": 1440}\n",
    "batch_size = 750\n",
    "bitmex_client = bitmex(test=False, api_key=bitmex_api_key, api_secret=bitmex_api_secret)\n",
    "binance_client = Client(api_key=binance_api_key, api_secret=binance_api_secret)\n",
    "\n",
    "### FUNCTIONS\n",
    "def minutes_of_new_data(symbol, kline_size, data, source):\n",
    "    if len(data) > 0:  old = parser.parse(data[\"timestamp\"].iloc[-1])\n",
    "    elif source == \"binance\": old = datetime.strptime('1 Jan 2017', '%d %b %Y')\n",
    "    elif source == \"bitmex\": old = bitmex_client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=1, reverse=False).result()[0][0]['timestamp']\n",
    "    if source == \"binance\": new = pd.to_datetime(binance_client.get_klines(symbol=symbol, interval=kline_size)[-1][0], unit='ms')\n",
    "    if source == \"bitmex\": new = bitmex_client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=1, reverse=True).result()[0][0]['timestamp']\n",
    "    return old, new\n",
    "\n",
    "def get_all_binance(symbol, kline_size, save = False):\n",
    "    filename = '%s-%s-data.csv' % (symbol, kline_size)\n",
    "    if os.path.isfile(filename): data_df = pd.read_csv(filename)\n",
    "    else: data_df = pd.DataFrame()\n",
    "    oldest_point, newest_point = minutes_of_new_data(symbol, kline_size, data_df, source = \"binance\")\n",
    "    delta_min = (newest_point - oldest_point).total_seconds()/60\n",
    "    available_data = math.ceil(delta_min/binsizes[kline_size])\n",
    "    if oldest_point == datetime.strptime('1 Jan 2017', '%d %b %Y'): print('Downloading all available %s data for %s. Be patient..!' % (kline_size, symbol))\n",
    "    else: print('Downloading %d minutes of new data available for %s, i.e. %d instances of %s data.' % (delta_min, symbol, available_data, kline_size))\n",
    "    klines = binance_client.get_historical_klines(symbol, kline_size, oldest_point.strftime(\"%d %b %Y %H:%M:%S\"), newest_point.strftime(\"%d %b %Y %H:%M:%S\"))\n",
    "    data = pd.DataFrame(klines, columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_av', 'trades', 'tb_base_av', 'tb_quote_av', 'ignore' ])\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "    if len(data_df) > 0:\n",
    "        temp_df = pd.DataFrame(data)\n",
    "        data_df = data_df.append(temp_df)\n",
    "    else: data_df = data\n",
    "    data_df.set_index('timestamp', inplace=True)\n",
    "    if save: data_df.to_pickle(bin_path + filename)\n",
    "    print('All caught up..!')\n",
    "    return data_df\n",
    "\n",
    "def get_all_bitmex(symbol, kline_size, save = False):\n",
    "    filename = '%s-%s-data.csv' % (symbol, kline_size)\n",
    "    if os.path.isfile(filename): data_df = pd.read_csv(filename)\n",
    "    else: data_df = pd.DataFrame()\n",
    "    oldest_point, newest_point = minutes_of_new_data(symbol, kline_size, data_df, source = \"bitmex\")\n",
    "    delta_min = (newest_point - oldest_point).total_seconds()/60\n",
    "    available_data = math.ceil(delta_min/binsizes[kline_size])\n",
    "    rounds = math.ceil(available_data / batch_size)\n",
    "    if rounds > 0:\n",
    "        print('Downloading %d minutes of new data available for %s, i.e. %d instances of %s data in %d rounds.' % (delta_min, symbol, available_data, kline_size, rounds))\n",
    "        for round_num in tqdm_notebook(range(rounds)):\n",
    "            time.sleep(1)\n",
    "            new_time = (oldest_point + timedelta(minutes = round_num * batch_size * binsizes[kline_size]))\n",
    "            data = bitmex_client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=batch_size, startTime = new_time).result()[0]\n",
    "            temp_df = pd.DataFrame(data)\n",
    "            data_df = pd.concat([data_df,temp_df], axis = 0)\n",
    "    data_df.set_index('timestamp', inplace=True)\n",
    "    if save and rounds > 0: data_df.to_pickle(bit_path + filename)\n",
    "    print('All caught up..!')\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "174957f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = ['BTCUSDT', 'XRPUSDT', 'BUSD/USDT', 'USDC/USDT', 'BNB/USDT', 'ADA/USDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da660a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading all available 1m data for BTCUSDT. Be patient..!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caaka\\anaconda3\\lib\\site-packages\\dateparser\\date_parser.py:35: PytzUsageWarning: The localize method is no longer necessary, as this time zone supports the fold attribute (PEP 495). For more details on migrating to a PEP 495-compliant implementation, see https://pytz-deprecation-shim.readthedocs.io/en/latest/migration.html\n",
      "  date_obj = stz.localize(date_obj)\n"
     ]
    }
   ],
   "source": [
    "for i in ticker:\n",
    "    data = get_all_binance(i, \"1m\", save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6728f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
